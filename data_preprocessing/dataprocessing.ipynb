{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5724ba53-7484-454b-81c4-f36b0bac939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c489002-f091-4eca-905f-810fa748f27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_files = glob.glob(os.path.join(\"D:/Datasets for sign language/Complete video dataset for indian sign language/ICSL_25/PKL_files_for_25_sentences\",\"*.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9677c96a-d2f9-48bf-8abd-757514cc5347",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets = [x.split(\"\\\\\")[-1][:-6] for x in video_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba85599c-ca58-4ace-9d02-224599fee743",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BRING_WATER_ME',\n",
       " 'BRING_WATER_ME',\n",
       " 'BRING_WATER_ME',\n",
       " 'BRING_WATER_ME',\n",
       " 'BRING_WATER_ME',\n",
       " 'COMB_YOU_HAIR',\n",
       " 'COMB_YOU_HAIR',\n",
       " 'COMB_YOU_HAIR',\n",
       " 'COMB_YOU_HAIR',\n",
       " 'COMB_YOU_HAIR',\n",
       " 'CONGRATULATIIONS',\n",
       " 'CONGRATULATIIONS',\n",
       " 'CONGRATULATIIONS',\n",
       " 'CONGRATULATIIONS',\n",
       " 'CONGRATULATIIONS',\n",
       " 'DONOT_HURT_ME',\n",
       " 'DONOT_HURT_ME',\n",
       " 'DONOT_HURT_ME',\n",
       " 'DONOT_HURT_ME',\n",
       " 'DONOT_HURT_ME',\n",
       " 'DONOT_MAKE_ME_ANGRY',\n",
       " 'DONOT_MAKE_ME_ANGRY',\n",
       " 'DONOT_MAKE_ME_ANGRY',\n",
       " 'DONOT_MAKE_ME_ANGRY',\n",
       " 'DONOT_MAKE_ME_ANGRY',\n",
       " 'DONOT_TAKE IT_HEART',\n",
       " 'DONOT_TAKE IT_HEART',\n",
       " 'DONOT_TAKE IT_HEART',\n",
       " 'DONOT_TAKE IT_HEART',\n",
       " 'DONOT_TAKE IT_HEART',\n",
       " 'DONOT_WORRY',\n",
       " 'DONOT_WORRY',\n",
       " 'DONOT_WORRY',\n",
       " 'DONOT_WORRY',\n",
       " 'DONOT_WORRY',\n",
       " 'DO_ME_FAVOUR',\n",
       " 'DO_ME_FAVOUR',\n",
       " 'DO_ME_FAVOUR',\n",
       " 'DO_ME_FAVOUR',\n",
       " 'DO_ME_FAVOUR',\n",
       " 'DO_YOU_NEED_SOMETHING',\n",
       " 'DO_YOU_NEED_SOMETHING',\n",
       " 'DO_YOU_NEED_SOMETHING',\n",
       " 'DO_YOU_NEED_SOMETHING',\n",
       " 'DO_YOU_NEED_SOMETHING',\n",
       " 'GO_SLEEP',\n",
       " 'GO_SLEEP',\n",
       " 'GO_SLEEP',\n",
       " 'GO_SLEEP',\n",
       " 'GO_SLEEP',\n",
       " 'HELP_ME',\n",
       " 'HELP_ME',\n",
       " 'HELP_ME',\n",
       " 'HELP_ME',\n",
       " 'HELP_ME',\n",
       " 'HE_CAME_TRAIN',\n",
       " 'HE_CAME_TRAIN',\n",
       " 'HE_CAME_TRAIN',\n",
       " 'HE_CAME_TRAIN',\n",
       " 'HE_CAME_TRAIN',\n",
       " 'HE_COMING_TODAY',\n",
       " 'HE_COMING_TODAY',\n",
       " 'HE_COMING_TODAY',\n",
       " 'HE_COMING_TODAY',\n",
       " 'HE_COMING_TODAY',\n",
       " 'HE_GO_INTO_ROOM',\n",
       " 'HE_GO_INTO_ROOM',\n",
       " 'HE_GO_INTO_ROOM',\n",
       " 'HE_GO_INTO_ROOM',\n",
       " 'HE_GO_INTO_ROOM',\n",
       " 'HE_SHE_MY_FRIEND',\n",
       " 'HE_SHE_MY_FRIEND',\n",
       " 'HE_SHE_MY_FRIEND',\n",
       " 'HE_SHE_MY_FRIEND',\n",
       " 'HE_SHE_MY_FRIEND',\n",
       " 'HI_HOW_YOU',\n",
       " 'HI_HOW_YOU',\n",
       " 'HI_HOW_YOU',\n",
       " 'HI_HOW_YOU',\n",
       " 'HI_HOW_YOU',\n",
       " 'HOW_DARE_YOU',\n",
       " 'HOW_DARE_YOU',\n",
       " 'HOW_DARE_YOU',\n",
       " 'HOW_DARE_YOU',\n",
       " 'HOW_DARE_YOU',\n",
       " 'HOW_I_HELP_YOU',\n",
       " 'HOW_I_HELP_YOU',\n",
       " 'HOW_I_HELP_YOU',\n",
       " 'HOW_I_HELP_YOU',\n",
       " 'HOW_I_HELP_YOU',\n",
       " 'HOW_I_TRUST_YOU',\n",
       " 'HOW_I_TRUST_YOU',\n",
       " 'HOW_I_TRUST_YOU',\n",
       " 'HOW_I_TRUST_YOU',\n",
       " 'HOW_I_TRUST_YOU',\n",
       " 'HOW_OLD_YOU',\n",
       " 'HOW_OLD_YOU',\n",
       " 'HOW_OLD_YOU',\n",
       " 'HOW_OLD_YOU',\n",
       " 'HOW_OLD_YOU',\n",
       " 'I_AFRAID_THAT',\n",
       " 'I_AFRAID_THAT',\n",
       " 'I_AFRAID_THAT',\n",
       " 'I_AFRAID_THAT',\n",
       " 'I_AFRAID_THAT',\n",
       " 'I_AGE',\n",
       " 'I_AGE',\n",
       " 'I_AGE',\n",
       " 'I_AGE',\n",
       " 'I_AGE',\n",
       " 'I_CRY',\n",
       " 'I_CRY',\n",
       " 'I_CRY',\n",
       " 'I_CRY',\n",
       " 'I_CRY',\n",
       " 'I_DONOT_AGREE',\n",
       " 'I_DONOT_AGREE',\n",
       " 'I_DONOT_AGREE',\n",
       " 'I_DONOT_AGREE',\n",
       " 'I_DONOT_AGREE',\n",
       " 'I_DONOT_LIKE_IT',\n",
       " 'I_DONOT_LIKE_IT',\n",
       " 'I_DONOT_LIKE_IT',\n",
       " 'I_DONOT_LIKE_IT',\n",
       " 'I_DONOT_LIKE_IT']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89a5dc19-a28f-46dd-99ed-2b0e092cde5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets = [x.split(\"_\") for x in train_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ad5b364-7be8-4be5-b17a-4c5d4d6d0c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a811f0df-65ee-4128-8f06-73e590770fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"D:/Datasets for sign language/Complete video dataset for indian sign language/ICSL_25/Complete_file/sample_\"+str(0)+\".pkl\", 'rb') as f:\n",
    "        data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1221b14a-8379-44b4-88fe-b8e5fc9ef047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([125, 2, 120, 27])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f82ca866-1f03-45e9-a9f8-e14688345d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57a1255a-516d-40b6-a7fc-60a10e7ba461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([125, 2, 120, 27])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efef7443-cf99-4120-aafb-72a6b66a9dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b03f8d9-f45f-4f85-9dd5-392e8958404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_inputs = torch.zeros(250,2,120,27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ecea022-8b19-4459-94ec-f22fc230e15f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop\n",
      "0\n",
      "0\n",
      "stop\n",
      "10\n",
      "5\n",
      "stop\n",
      "20\n",
      "10\n",
      "stop\n",
      "30\n",
      "15\n",
      "stop\n",
      "40\n",
      "20\n",
      "stop\n",
      "50\n",
      "25\n",
      "stop\n",
      "60\n",
      "30\n",
      "stop\n",
      "70\n",
      "35\n",
      "stop\n",
      "80\n",
      "40\n",
      "stop\n",
      "90\n",
      "45\n",
      "stop\n",
      "100\n",
      "50\n",
      "stop\n",
      "110\n",
      "55\n",
      "stop\n",
      "120\n",
      "60\n",
      "stop\n",
      "130\n",
      "65\n",
      "stop\n",
      "140\n",
      "70\n",
      "stop\n",
      "150\n",
      "75\n",
      "stop\n",
      "160\n",
      "80\n",
      "stop\n",
      "170\n",
      "85\n",
      "stop\n",
      "180\n",
      "90\n",
      "stop\n",
      "190\n",
      "95\n",
      "stop\n",
      "200\n",
      "100\n",
      "stop\n",
      "210\n",
      "105\n",
      "stop\n",
      "220\n",
      "110\n",
      "stop\n",
      "230\n",
      "115\n",
      "stop\n",
      "240\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "m = 0\n",
    "n = 0\n",
    "\n",
    "new_train_target = []\n",
    "\n",
    "for i in range(0,125,5):\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    new_train_inputs[m+0] = train_input[i+0]\n",
    "    #new_train_inputs[m+0] = new_train_inputs[m+0] + (torch.empty(2,120,27).normal_(mean=0,std=1)*0.01)\n",
    "    new_train_target.append(train_targets[n])\n",
    "    \n",
    "    new_train_inputs[m+1] = train_input[i+1]\n",
    "    #new_train_inputs[m+1] = new_train_inputs[m+1] + (torch.empty(2,120,27).normal_(mean=0,std=1)*0.01)    \n",
    "    new_train_target.append(train_targets[n])\n",
    "    \n",
    "    new_train_inputs[m+2] = train_input[i+2]\n",
    "    #new_train_inputs[m+2] = new_train_inputs[m+2] + (torch.empty(2,120,27).normal_(mean=0,std=1)*0.01) \n",
    "    new_train_target.append(train_targets[n])\n",
    "    \n",
    "    new_train_inputs[m+3] = train_input[i+3]\n",
    "    #new_train_inputs[m+3] = new_train_inputs[m+3] + (torch.empty(2,120,27).normal_(mean=0,std=1)*0.01)\n",
    "    new_train_target.append(train_targets[n])\n",
    "\n",
    "    new_train_inputs[m+4] = train_input[i+4]\n",
    "    #new_train_inputs[m+4] = new_train_inputs[m+4] + (torch.empty(2,120,27).normal_(mean=0,std=1)*0.01)\n",
    "    new_train_target.append(train_targets[n])\n",
    "\n",
    "    \n",
    "    new_train_inputs[m+5] = train_input[i+0]+(torch.empty(2,120,27).normal_(mean=0,std=1)*0.01) \n",
    "    new_train_target.append(train_targets[n])\n",
    "    \n",
    "    #new_train_inputs[m+6] = train_input[i][3]\n",
    "    #new_train_target.append(train_targets[n])\n",
    "    \n",
    "    new_train_inputs[m+6] = train_input[i+1]+(torch.empty(2,120,27).normal_(mean=0,std=1)*0.01)   \n",
    "    new_train_target.append(train_targets[n])\n",
    "    \n",
    "    \n",
    "    new_train_inputs[m+7] = train_input[i+2]+(torch.empty(2,120,27).normal_(mean=0,std=1)*0.01)\n",
    "    new_train_target.append(train_targets[n])\n",
    "    #new_train_inputs[i+9] = (train_input[i][0]+train_input[i][1]+train_input[i][2]+train_input[i][3])/4\n",
    "    #new_train_target.append(train_target[i])\n",
    "\n",
    "    #new_train_inputs[m+9] = train_input[i][4]\n",
    "    #new_train_target.append(train_targets[n])\n",
    "\n",
    "    new_train_inputs[m+8] = train_input[i+3]+(torch.empty(2,120,27).normal_(mean=0,std=1)*0.01) \n",
    "    new_train_target.append(train_targets[n])\n",
    "\n",
    "    new_train_inputs[m+9] = train_input[i+4]+(torch.empty(2,120,27).normal_(mean=0,std=1)*0.01)\n",
    "    new_train_target.append(train_targets[n])\n",
    "    \n",
    "    \n",
    "    #new_train_inputs[m+10] = (train_input[i][2]+train_input[i][3])/2\n",
    "    #new_train_inputs[m+10] = new_train_inputs[m+10] + (torch.empty(2,120,27).normal_(mean=0,std=1)*0.01)\n",
    "    #new_train_target.append(train_targets[n])\n",
    "\n",
    "    #new_train_inputs[m+11] = (train_input[i][1]+train_input[i][4])/2\n",
    "    #new_train_inputs[m+11] = new_train_inputs[m+11] + (torch.empty(2,120,27).normal_(mean=0,std=1)*0.01)\n",
    "    #new_train_target.append(train_targets[n])\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(\"stop\")\n",
    "    print(m)\n",
    "    print(n)\n",
    "    m = m+10\n",
    "    n = n+5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d68f3365-4c67-4419-813a-f8fae3b8cee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([250, 2, 120, 27])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1803a40b-5dc3-4874-b21d-5c41942e4c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee617c8f-8a16-4b25-8519-bcce92ad8047",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"D:/Datasets for sign language/Complete video dataset for indian sign language/ICSL_25/Complete_file/ICSL_25_train_targets.pkl\", 'wb') as handle:\n",
    "    pickle.dump(new_train_target, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25cc6a3a-895f-453c-9e27-42b883e4d810",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_inputs = torch.zeros(125,2,120,27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4b4c0d6-daf8-4282-a277-8b704e9e2b1d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop\n",
      "0\n",
      "0\n",
      "stop\n",
      "5\n",
      "5\n",
      "stop\n",
      "10\n",
      "10\n",
      "stop\n",
      "15\n",
      "15\n",
      "stop\n",
      "20\n",
      "20\n",
      "stop\n",
      "25\n",
      "25\n",
      "stop\n",
      "30\n",
      "30\n",
      "stop\n",
      "35\n",
      "35\n",
      "stop\n",
      "40\n",
      "40\n",
      "stop\n",
      "45\n",
      "45\n",
      "stop\n",
      "50\n",
      "50\n",
      "stop\n",
      "55\n",
      "55\n",
      "stop\n",
      "60\n",
      "60\n",
      "stop\n",
      "65\n",
      "65\n",
      "stop\n",
      "70\n",
      "70\n",
      "stop\n",
      "75\n",
      "75\n",
      "stop\n",
      "80\n",
      "80\n",
      "stop\n",
      "85\n",
      "85\n",
      "stop\n",
      "90\n",
      "90\n",
      "stop\n",
      "95\n",
      "95\n",
      "stop\n",
      "100\n",
      "100\n",
      "stop\n",
      "105\n",
      "105\n",
      "stop\n",
      "110\n",
      "110\n",
      "stop\n",
      "115\n",
      "115\n",
      "stop\n",
      "120\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "m = 0\n",
    "n = 0\n",
    "\n",
    "new_test_target = []\n",
    "\n",
    "for i in range(0,125,5):\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    new_test_inputs[m+0] = train_input[i+0] + (torch.empty(2,120,27).normal_(mean=0,std=1)*0.01)\n",
    "    new_test_target.append(train_targets[n])\n",
    "    \n",
    "    new_test_inputs[m+1] = train_input[i+1] + (torch.empty(2,120,27).normal_(mean=0,std=1)*0.01)\n",
    "    new_test_target.append(train_targets[n])\n",
    "    \n",
    "        \n",
    "    new_test_inputs[m+2] = train_input[i+2] + (torch.empty(2,120,27).normal_(mean=0,std=1)*0.01)\n",
    "    new_test_target.append(train_targets[n])\n",
    "    \n",
    "    new_test_inputs[m+3] = train_input[i+3] + (torch.empty(2,120,27).normal_(mean=0,std=1)*0.01)\n",
    "    new_test_target.append(train_targets[n])\n",
    "    \n",
    "    new_test_inputs[m+4] = train_input[i+4] + (torch.empty(2,120,27).normal_(mean=0,std=1)*0.01)\n",
    "    new_test_target.append(train_targets[n])\n",
    "    \n",
    "\n",
    "\n",
    "    print(\"stop\")\n",
    "    print(m)\n",
    "    print(n)\n",
    "    m = m+5\n",
    "    n = n+5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "529c4b79-d86e-4108-9430-5bd004cfcc6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([125, 2, 120, 27])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74b67a02-ae14-4d67-8244-83a36156efc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "659ea9c9-8b00-4a9d-a6b7-e9c215a8f883",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['BRING', 'WATER', 'ME'],\n",
       " ['BRING', 'WATER', 'ME'],\n",
       " ['BRING', 'WATER', 'ME'],\n",
       " ['BRING', 'WATER', 'ME'],\n",
       " ['BRING', 'WATER', 'ME'],\n",
       " ['COMB', 'YOU', 'HAIR'],\n",
       " ['COMB', 'YOU', 'HAIR'],\n",
       " ['COMB', 'YOU', 'HAIR'],\n",
       " ['COMB', 'YOU', 'HAIR'],\n",
       " ['COMB', 'YOU', 'HAIR'],\n",
       " ['CONGRATULATIIONS'],\n",
       " ['CONGRATULATIIONS'],\n",
       " ['CONGRATULATIIONS'],\n",
       " ['CONGRATULATIIONS'],\n",
       " ['CONGRATULATIIONS'],\n",
       " ['DONOT', 'HURT', 'ME'],\n",
       " ['DONOT', 'HURT', 'ME'],\n",
       " ['DONOT', 'HURT', 'ME'],\n",
       " ['DONOT', 'HURT', 'ME'],\n",
       " ['DONOT', 'HURT', 'ME'],\n",
       " ['DONOT', 'MAKE', 'ME', 'ANGRY'],\n",
       " ['DONOT', 'MAKE', 'ME', 'ANGRY'],\n",
       " ['DONOT', 'MAKE', 'ME', 'ANGRY'],\n",
       " ['DONOT', 'MAKE', 'ME', 'ANGRY'],\n",
       " ['DONOT', 'MAKE', 'ME', 'ANGRY'],\n",
       " ['DONOT', 'TAKE IT', 'HEART'],\n",
       " ['DONOT', 'TAKE IT', 'HEART'],\n",
       " ['DONOT', 'TAKE IT', 'HEART'],\n",
       " ['DONOT', 'TAKE IT', 'HEART'],\n",
       " ['DONOT', 'TAKE IT', 'HEART'],\n",
       " ['DONOT', 'WORRY'],\n",
       " ['DONOT', 'WORRY'],\n",
       " ['DONOT', 'WORRY'],\n",
       " ['DONOT', 'WORRY'],\n",
       " ['DONOT', 'WORRY'],\n",
       " ['DO', 'ME', 'FAVOUR'],\n",
       " ['DO', 'ME', 'FAVOUR'],\n",
       " ['DO', 'ME', 'FAVOUR'],\n",
       " ['DO', 'ME', 'FAVOUR'],\n",
       " ['DO', 'ME', 'FAVOUR'],\n",
       " ['DO', 'YOU', 'NEED', 'SOMETHING'],\n",
       " ['DO', 'YOU', 'NEED', 'SOMETHING'],\n",
       " ['DO', 'YOU', 'NEED', 'SOMETHING'],\n",
       " ['DO', 'YOU', 'NEED', 'SOMETHING'],\n",
       " ['DO', 'YOU', 'NEED', 'SOMETHING'],\n",
       " ['GO', 'SLEEP'],\n",
       " ['GO', 'SLEEP'],\n",
       " ['GO', 'SLEEP'],\n",
       " ['GO', 'SLEEP'],\n",
       " ['GO', 'SLEEP'],\n",
       " ['HELP', 'ME'],\n",
       " ['HELP', 'ME'],\n",
       " ['HELP', 'ME'],\n",
       " ['HELP', 'ME'],\n",
       " ['HELP', 'ME'],\n",
       " ['HE', 'CAME', 'TRAIN'],\n",
       " ['HE', 'CAME', 'TRAIN'],\n",
       " ['HE', 'CAME', 'TRAIN'],\n",
       " ['HE', 'CAME', 'TRAIN'],\n",
       " ['HE', 'CAME', 'TRAIN'],\n",
       " ['HE', 'COMING', 'TODAY'],\n",
       " ['HE', 'COMING', 'TODAY'],\n",
       " ['HE', 'COMING', 'TODAY'],\n",
       " ['HE', 'COMING', 'TODAY'],\n",
       " ['HE', 'COMING', 'TODAY'],\n",
       " ['HE', 'GO', 'INTO', 'ROOM'],\n",
       " ['HE', 'GO', 'INTO', 'ROOM'],\n",
       " ['HE', 'GO', 'INTO', 'ROOM'],\n",
       " ['HE', 'GO', 'INTO', 'ROOM'],\n",
       " ['HE', 'GO', 'INTO', 'ROOM'],\n",
       " ['HE', 'SHE', 'MY', 'FRIEND'],\n",
       " ['HE', 'SHE', 'MY', 'FRIEND'],\n",
       " ['HE', 'SHE', 'MY', 'FRIEND'],\n",
       " ['HE', 'SHE', 'MY', 'FRIEND'],\n",
       " ['HE', 'SHE', 'MY', 'FRIEND'],\n",
       " ['HI', 'HOW', 'YOU'],\n",
       " ['HI', 'HOW', 'YOU'],\n",
       " ['HI', 'HOW', 'YOU'],\n",
       " ['HI', 'HOW', 'YOU'],\n",
       " ['HI', 'HOW', 'YOU'],\n",
       " ['HOW', 'DARE', 'YOU'],\n",
       " ['HOW', 'DARE', 'YOU'],\n",
       " ['HOW', 'DARE', 'YOU'],\n",
       " ['HOW', 'DARE', 'YOU'],\n",
       " ['HOW', 'DARE', 'YOU'],\n",
       " ['HOW', 'I', 'HELP', 'YOU'],\n",
       " ['HOW', 'I', 'HELP', 'YOU'],\n",
       " ['HOW', 'I', 'HELP', 'YOU'],\n",
       " ['HOW', 'I', 'HELP', 'YOU'],\n",
       " ['HOW', 'I', 'HELP', 'YOU'],\n",
       " ['HOW', 'I', 'TRUST', 'YOU'],\n",
       " ['HOW', 'I', 'TRUST', 'YOU'],\n",
       " ['HOW', 'I', 'TRUST', 'YOU'],\n",
       " ['HOW', 'I', 'TRUST', 'YOU'],\n",
       " ['HOW', 'I', 'TRUST', 'YOU'],\n",
       " ['HOW', 'OLD', 'YOU'],\n",
       " ['HOW', 'OLD', 'YOU'],\n",
       " ['HOW', 'OLD', 'YOU'],\n",
       " ['HOW', 'OLD', 'YOU'],\n",
       " ['HOW', 'OLD', 'YOU'],\n",
       " ['I', 'AFRAID', 'THAT'],\n",
       " ['I', 'AFRAID', 'THAT'],\n",
       " ['I', 'AFRAID', 'THAT'],\n",
       " ['I', 'AFRAID', 'THAT'],\n",
       " ['I', 'AFRAID', 'THAT'],\n",
       " ['I', 'AGE'],\n",
       " ['I', 'AGE'],\n",
       " ['I', 'AGE'],\n",
       " ['I', 'AGE'],\n",
       " ['I', 'AGE'],\n",
       " ['I', 'CRY'],\n",
       " ['I', 'CRY'],\n",
       " ['I', 'CRY'],\n",
       " ['I', 'CRY'],\n",
       " ['I', 'CRY'],\n",
       " ['I', 'DONOT', 'AGREE'],\n",
       " ['I', 'DONOT', 'AGREE'],\n",
       " ['I', 'DONOT', 'AGREE'],\n",
       " ['I', 'DONOT', 'AGREE'],\n",
       " ['I', 'DONOT', 'AGREE'],\n",
       " ['I', 'DONOT', 'LIKE', 'IT'],\n",
       " ['I', 'DONOT', 'LIKE', 'IT'],\n",
       " ['I', 'DONOT', 'LIKE', 'IT'],\n",
       " ['I', 'DONOT', 'LIKE', 'IT'],\n",
       " ['I', 'DONOT', 'LIKE', 'IT']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aba059f2-2f75-4fb3-8440-275be2366e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D:/Datasets for sign language/Complete video dataset for indian sign language/ICSL_25/Complete_file/ICSL_25_test_targets.pkl\", 'wb') as handle:\n",
    "    pickle.dump(new_test_target, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e64d24-759a-4070-b51e-269d3325f70f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
